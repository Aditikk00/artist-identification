{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import zipfile as z\n",
    "from PIL import Image\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import os\n",
    "from sklearn import preprocessing# label encoding\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, SubsetRandomSampler, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (15, 5)\n",
    "plt.rcParams['font.size'] = '5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entire Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('all_data_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of artists\n",
    "len(df['artist'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing artist names?\n",
    "df['artist'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num paintings per artist\n",
    "by_artist = pd.DataFrame(df['artist'].value_counts().reset_index())\n",
    "by_artist.columns = ['artist','count']\n",
    "by_artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of artists with > 200 paintings\n",
    "len(by_artist[by_artist['count'] >= 200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove data where < 200 paintings per artist\n",
    "by_artist = by_artist[by_artist['count'] >= 200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(by_artist['count'])\n",
    "plt.title('Distribution of num paintings per artist')\n",
    "plt.xlabel('num paintings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing artists from the main df that have < 200 paintings\n",
    "df_200 = df[df['artist'].isin(by_artist['artist'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_200.shape # 37452 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_200['artist'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subset: Train 1 and Train 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__lines below commented so don't need to create df_sub from scratch each time - just load saved pickle file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entire training set to large so downloading subset train 1\n",
    "\n",
    "# filenames_train1 = []\n",
    "# with z.ZipFile('train_1.zip', 'r') as zip:\n",
    "#     for info in zip.infolist():\n",
    "#         name = info.filename.split('/')\n",
    "#         filenames_train1.append(name[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entire training set to large so downloading subset train 1\n",
    "\n",
    "# filenames_train2 = []\n",
    "# with z.ZipFile('train_2.zip', 'r') as zip:\n",
    "#     for info in zip.infolist():\n",
    "#         name = info.filename.split('/')\n",
    "#         filenames_train2.append(name[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train1_df = df[df['new_filename'].isin(filenames_train1)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train2_df = df[df['new_filename'].isin(filenames_train2)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train1_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train2_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving train1_df and train2_df\n",
    "# train1_df.to_pickle(\"train1_df.pkl\")\n",
    "# train2_df.to_pickle(\"train2_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train1 and train2 dataframes from pickle file\n",
    "train1_df = pd.read_pickle(\"train1_df.pkl\")\n",
    "train2_df = pd.read_pickle(\"train2_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train1_df.shape)\n",
    "train1_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train2_df.shape)\n",
    "train2_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of unique artists in train1 and train2\n",
    "print(\"train1 num artists: \", len(train1_df['artist'].unique()))\n",
    "print(\"train2 num artists: \", len(train2_df['artist'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining both tables\n",
    "df_sub = pd.concat([train1_df,train2_df], ignore_index=True)\n",
    "print(df_sub.shape)\n",
    "# drop 'index' col\n",
    "df_sub.drop('index', axis=1, inplace=True)\n",
    "df_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of unique artists\n",
    "len(df_sub['artist'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#merging train 1 and train 2 folders (unzip them first)\n",
    "#import os\n",
    "#import shutil\n",
    "\n",
    "# #Path of source directory & destination directory\n",
    "#src_directory = 'train_2'\n",
    "#dst_directory = 'train_1'\n",
    "\n",
    "# # Extract file from Source directory and move to Destination directory\n",
    "#for file in os.listdir(src_directory):\n",
    "     #src_file = os.path.join(src_directory, file)\n",
    "     #dest_file = os.path.join(dst_directory, file)\n",
    "     #shutil.move(src_file, dest_file)\n",
    "\n",
    "# all should be in 'train_1', compress it for storage renamed as train.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "merged files in train.zip under train_1 directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking at some images\n",
    "archive = z.ZipFile('train.zip', 'r')\n",
    "file = df_sub.loc[2]['new_filename']\n",
    "imgdata = archive.open('train_1/'+file)\n",
    "img = Image.open(imgdata)\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "file = df_sub.loc[19500]['new_filename']\n",
    "imgdata = archive.open('train_1/'+file)\n",
    "img = Image.open(imgdata)\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub['artist'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__largest number of paintings per artist in df_sub is 119 (compared to 500 in entire training data)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_artist_1 = pd.DataFrame(df_sub['artist'].value_counts().reset_index())\n",
    "by_artist_1.columns = ['artist','count']\n",
    "by_artist_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(by_artist_1['count'])\n",
    "plt.title('Distribution of num paintings per artist- Train1,2')\n",
    "plt.xlabel('num paintings')\n",
    "plt.xticks(range(0, 119,3))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of artists with > 80 paintings\n",
    "len(by_artist_1[by_artist_1['count'] >= 80])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_artist_1 = by_artist_1[by_artist_1['count'] >= 80]\n",
    "# removing artists from the main df that have < 80 paintings\n",
    "df_80 = df_sub[df_sub['artist'].isin(by_artist_1['artist'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_80.shape)\n",
    "print(\"num artists: \", len(df_80['artist'].unique()))\n",
    "df_80.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__df_80 has data from df_sub with artists having >= 80 paintings (max = 119)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_80.groupby('artist').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# balancing the classes (making all artists have 80 paintings)\n",
    "X = df_80.drop('artist', axis=1)\n",
    "y = df_80['artist']\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_rus, y_rus = rus.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_rus.shape)\n",
    "print(36*81)\n",
    "y_rus.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resampled so dataset is now 36 artists each with 81 paintings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving X_rus and y_rus as pickle files\n",
    "# X_rus.to_pickle(\"X_rus.pkl\")\n",
    "# y_rus.to_pickle(\"y_rus.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_rus = pd.read_pickle(\"X_rus.pkl\")\n",
    "# y_rus = pd.read_pickle(\"y_rus.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='genre', data=X_rus)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Distribution of Genres')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resizing images to 256x256 according to paper. Also normalizing and creating dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory = 'train_1'\n",
    "\n",
    "# for filename in os.listdir(directory):\n",
    "#     try:\n",
    "#         if filename.endswith('.jpg'):\n",
    "#             img_path = os.path.join(directory, filename)\n",
    "#             with Image.open(img_path) as img:\n",
    "#                 img_resized = img.resize((256, 256), resample=Image.BILINEAR)\n",
    "#                 img_resized.convert('RGB').save(os.path.join(directory, filename))\n",
    "#     except:\n",
    "#         print(f\"Could not process image {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove record of corrupted image file 101947.jpg\n",
    "X_rus[X_rus['new_filename']=='101947.jpg'] #not included after resampling anyways"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Images resized to 256x256__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = df_sub.loc[19400]['new_filename'] \n",
    "img = Image.open(os.path.join('train_1', filename))\n",
    "plt.imshow(img)\n",
    "print(img.size)  # Should print (256, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforming image - normalization improves performance\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), \n",
    "     transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)) # applying ImageNet normalization\n",
    "    ])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at transformed image\n",
    "filename = df_sub.loc[19400]['new_filename'] \n",
    "img = Image.open(os.path.join('train_1', filename))\n",
    "tr_img = transform(img)\n",
    "plt.imshow(tr_img.numpy().transpose(1,2,0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder() # one hot encoding instead? but 36 classes\n",
    "artists = list(y_rus.unique())\n",
    "le.fit(artists)\n",
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = le.transform(y_rus)\n",
    "y_rus,l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataloaders, batch size etc\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self,img_dir, X,y, transformation): # pass X_rus, y_rus, img_dir='train_1' for training\n",
    "        self.transformation = transform\n",
    "        # is encoder needed?\n",
    "        self.encoder = le\n",
    "        self.img_dir = img_dir\n",
    "        self.feats, self.labels = self.get_all(self.img_dir,X,y)\n",
    "        \n",
    "    def get_all(self,img_dir,X,y):\n",
    "        images = []\n",
    "        labels = []\n",
    "        \n",
    "        for index, row in X.iterrows():\n",
    "            file = row['new_filename']\n",
    "            img = Image.open(os.path.join(img_dir, file)) \n",
    "            data = self.transformation(img)\n",
    "            images.append(data)\n",
    "            \n",
    "            \n",
    "        labels = self.encoder.transform(y)\n",
    "        \n",
    "        \n",
    "        images = torch.stack(images)\n",
    "        labels = torch.LongTensor(labels)\n",
    "        return images, labels\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self,item):\n",
    "        return self.feats[item], self.labels[item]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to do similar for test data^"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainset = CustomImageDataset('train_1',X_rus,y_rus,transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(trainset,\"trainset.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load saved Dataset\n",
    "trainset = torch.load(\"trainset.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and val [80:20]\n",
    "batch_size= 32\n",
    "labels = trainset.labels.numpy()\n",
    "train_indices, val_indices = train_test_split(np.arange(len(labels)),test_size=0.2,\n",
    "                                              shuffle=True,random_state=42,stratify=labels)\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "val_sampler = SubsetRandomSampler(val_indices)\n",
    "train_loader = DataLoader(trainset, batch_size=batch_size, sampler=train_sampler,drop_last=True)\n",
    "val_loader = DataLoader(trainset, batch_size=batch_size, sampler=val_sampler,drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline CNN\n",
    "Based on: http://cs229.stanford.edu/proj2018/report/41.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") \n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNBase(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNBase,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3,16,3,padding=1)\n",
    "        self.conv2 = nn.Conv2d(16,16,3,padding=1)\n",
    "        self.conv3 = nn.Conv2d(16,16,3,padding=1)\n",
    "        self.conv4 = nn.Conv2d(16,32,3,padding=1)\n",
    "        self.conv5 = nn.Conv2d(32,128,3,padding=1)\n",
    "        self.conv6 = nn.Conv2d(128,256,3,padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.bn16 = nn.BatchNorm2d(16)\n",
    "        self.bn32 = nn.BatchNorm2d(32)\n",
    "        self.bn128 = nn.BatchNorm2d(128)\n",
    "        self.bn256 = nn.BatchNorm2d(256)\n",
    "        self.dropout = nn.Dropout2d(p=0.5)\n",
    "        self.fc1 = nn.Linear(16384,2048)\n",
    "        self.fc2 = nn.Linear(2048,num_classes)\n",
    "        self.pool = nn.MaxPool2d(2) \n",
    "        #self.softmax = nn.Softmax(dim=1) need to remove during training as cross entropy loss already has softmax\n",
    "        \n",
    "    def forward(self,x):\n",
    "        #print(\"start: \", x.shape)\n",
    "        x = self.relu(self.bn16(self.conv1(x)))\n",
    "        #print(\"conv1: \", x.shape)\n",
    "        x = self.pool(self.relu(self.bn16(self.conv2(x))))\n",
    "        #print(\"conv2: \", x.shape)\n",
    "        x = self.pool(self.relu(self.bn16(self.conv3(x))))\n",
    "        #print(\"conv3: \", x.shape)\n",
    "        x = self.pool(self.relu(self.bn32(self.conv4(x))))\n",
    "        #print(\"conv4: \", x.shape)\n",
    "        x = self.pool(self.relu(self.bn128(self.conv5(x))))\n",
    "        #print(\"conv5: \", x.shape)\n",
    "        x = self.pool(self.relu(self.bn256(self.conv6(x))))\n",
    "        #print(\"conv6: \", x.shape)\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        #print(\"flatten: \", x.shape)\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        #print(\"fc1: \", x.shape)\n",
    "        x = self.fc2(x)\n",
    "        #print(\"fc2: \", x.shape)\n",
    "        x = self.dropout(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_base = CNNBase()\n",
    "cnn_base.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()\n",
    "opt = optim.Adam(cnn_base.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, data in enumerate(train_loader, 0):\n",
    "    inputs,labels = data\n",
    "    print(inputs.shape)\n",
    "    print(labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "best_model_path = 'best_model.pt'\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    batch_loss = []\n",
    "    cnn_base.train()\n",
    "    \n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs,labels = data\n",
    "        # Move the inputs to the specified device.\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # Zero the parameter gradients.\n",
    "        opt.zero_grad()\n",
    "        \n",
    "        # forward step\n",
    "        outputs = cnn_base(inputs)\n",
    "        loss = loss_func(outputs,labels)\n",
    "        \n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # update parameters\n",
    "        opt.step()\n",
    "        \n",
    "        batch_loss.append(loss.data.item())\n",
    "        \n",
    "    train_loss = np.mean(batch_loss)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    cnn_base.eval()\n",
    "    batch_loss = []\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(val_loader, 0):\n",
    "            inputs,labels = data\n",
    "            # Move the inputs to the specified device.\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # forward step\n",
    "            outputs = cnn_base(inputs)\n",
    "            loss = loss_func(outputs,labels)\n",
    "\n",
    "            batch_loss.append(loss.data.item())\n",
    "        val_loss = np.mean(batch_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(cnn_base.state_dict(), best_model_path)\n",
    "    #if epoch%10==0:\n",
    "    print(f\"[{epoch+1}/{epochs}] Training loss: {train_loss:.4f}\\t Validation loss: {val_loss:.4f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(cnn_base.state_dict(), 'latest_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python program to store list to file using pickle module\n",
    "import pickle\n",
    "\n",
    "# write list to binary file\n",
    "def write_list(a_list, file_name):\n",
    "    # store list in binary file so 'wb' mode\n",
    "    with open(file_name, 'wb') as fp:\n",
    "        pickle.dump(a_list, fp)\n",
    "        print('Done writing list into a binary file')\n",
    "\n",
    "# Read list to memory\n",
    "def read_list(file_name):\n",
    "    # for reading also binary mode is important\n",
    "    with open(file_name, 'rb') as fp:\n",
    "        n_list = pickle.load(fp)\n",
    "        return n_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_list(train_losses,'train_losses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_list(val_losses,'val_losses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the loss diagram\n",
    "plt.plot(train_losses,label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.legend(loc='best')\n",
    "plt.ylabel('Mean Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.title(f\"Loss graph during the process of training the Baseline CNN.\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model has overfit. Likely because our data size is much smaller than what the paper used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create test df\n",
    "test_df = df[df['in_train']==False]\n",
    "print(test_df.shape)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only using those artists that model was trained on\n",
    "artists = list(y_rus.unique())\n",
    "test_df = test_df[test_df['artist'].isin(artists)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_df.shape)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking a smaller stratified subset of test_df\n",
    "test_df['artist'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__randomly sample 30 artworks of each artist__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sub = test_df.groupby('artist', group_keys=False).apply(lambda x: x.sample(30, random_state = 42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_sub.shape)\n",
    "test_sub['artist'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize test images\n",
    "# directory = 'test'\n",
    "\n",
    "# for filename in os.listdir(directory):\n",
    "#     try:\n",
    "#         if filename.endswith('.jpg'):\n",
    "#             img_path = os.path.join(directory, filename)\n",
    "#             with Image.open(img_path) as img:\n",
    "#                 img_resized = img.resize((256, 256), resample=Image.BILINEAR)\n",
    "#                 img_resized.convert('RGB').save(os.path.join(directory, filename))\n",
    "#     except:\n",
    "#         print(f\"Could not process image {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corrupted files\n",
    "test_sub[test_sub['new_filename'].isin(['20153.jpg','9989.jpg','100532.jpg','18649.jpg','24000.jpg'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = test_sub.loc[39942]['new_filename'] \n",
    "img = Image.open(os.path.join('test', filename))\n",
    "plt.imshow(img)\n",
    "print(img.size)  # Should print (256, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_art = test_sub['artist'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_test = preprocessing.LabelEncoder()\n",
    "le_test.fit(test_art)\n",
    "le_test.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataloaders, batch size etc\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self,img_dir, dataframe, transformation): \n",
    "        self.transformation = transform\n",
    "       \n",
    "        self.encoder = le_test\n",
    "        self.img_dir = img_dir\n",
    "        self.feats, self.labels = self.get_all(self.img_dir,dataframe)\n",
    "        \n",
    "    def get_all(self,img_dir,dataframe):\n",
    "        images = []\n",
    "        labels = []\n",
    "        \n",
    "        for index, row in dataframe.iterrows():\n",
    "            file = row['new_filename']\n",
    "            img = Image.open(os.path.join(img_dir, file)) \n",
    "            data = self.transformation(img)\n",
    "            images.append(data)\n",
    "            \n",
    "            artist = row['artist']\n",
    "            label = self.encoder.transform([artist])[0]\n",
    "            labels.append(label)\n",
    "        \n",
    "        #labels = self.encoder.transform(y)\n",
    "        \n",
    "        images = torch.stack(images)\n",
    "        labels = torch.LongTensor(labels)\n",
    "        return images, labels\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self,item):\n",
    "        return self.feats[item], self.labels[item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = TestDataset('test',test_sub,transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(testset,'testset.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(testset, batch_size=batch_size ,drop_last=True, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, data in enumerate(test_loader, 0):\n",
    "    inp,out = data\n",
    "    print(out) #output is 32 because batch size is 32. each value is a label?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate on test set\n",
    "def evaluate(model, test_dataloader, device=device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    ground = []\n",
    "#     total_correct = 0\n",
    "#     total_samples = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(test_dataloader, 0):\n",
    "            inputs,labels = data\n",
    "            # Move the inputs to the specified device.\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            output = model(inputs)\n",
    "            \n",
    "            output_idx = torch.argmax(output,dim=1)\n",
    "            \n",
    "            predictions.append(output_idx.numpy())\n",
    "            ground.append(labels.numpy())\n",
    "            \n",
    "#             _, predicted = torch.max(output.data, 1)\n",
    "#             total_correct += (predicted == labels).sum().item()\n",
    "#             total_samples += labels.size(0)\n",
    "            \n",
    "#     accuracy = 100 * (total_correct / total_samples)\n",
    "#     print(f'Test Accuracy: {accuracy:.2f}%')\n",
    "    \n",
    "    return predictions, ground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNNBase()\n",
    "model.load_state_dict(torch.load('best_model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, ground = evaluate(model,test_loader)\n",
    "y_true = np.concatenate(ground, axis=0)\n",
    "y_pred = np.concatenate(pred, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_true), len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rc_file_defaults() # to remove the sns darkgrid style\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "classes = list(le.classes_)\n",
    "sns.heatmap(cm, annot=True, cmap='Blues', fmt='g', xticklabels=classes, yticklabels=classes)\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing Accuracy: 9%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rn18 = models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(le.classes_)\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify last layer\n",
    "rn18.fc = nn.Sequential(\n",
    "    nn.Linear(rn18.fc.in_features, num_classes),\n",
    "    nn.Softmax(dim=1)) # can remove softmax?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze the model\n",
    "for param in rn18.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in rn18.fc.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model- only the last layer\n",
    "optimizer = optim.Adam(rn18.fc.parameters(), lr=0.0001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_rn18 = []\n",
    "val_loss_rn18 = []\n",
    "best_val_loss = float('inf')\n",
    "patience = 3\n",
    "early_stop_counter = 0\n",
    "rn18_path = 'best_rn18.pt'\n",
    "\n",
    "for epoch in range(10):\n",
    "    rn18.train()\n",
    "    batch_loss = []\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs,labels = data\n",
    "        # Move the inputs to the specified device.\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # Zero the parameter gradients.\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward step\n",
    "        outputs = rn18(inputs)\n",
    "        loss = criterion(outputs,labels)\n",
    "        \n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        batch_loss.append(loss.data.item())\n",
    "        \n",
    "    train_loss = np.mean(batch_loss)\n",
    "    train_loss_rn18.append(train_loss)\n",
    "    \n",
    "    rn18.eval()\n",
    "    batch_loss = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(val_loader, 0):\n",
    "            inputs,labels = data\n",
    "            # Move the inputs to the specified device.\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # forward step\n",
    "            outputs = rn18(inputs)\n",
    "            loss = criterion(outputs,labels)\n",
    "\n",
    "            batch_loss.append(loss.data.item())\n",
    "            \n",
    "        val_loss = np.mean(batch_loss)\n",
    "        val_loss_rn18.append(val_loss)\n",
    "        \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        early_stop_counter = 0\n",
    "        torch.save(rn18.state_dict(), rn18_path)\n",
    "    else:\n",
    "        early_stop_counter+=1 \n",
    "        if early_stop_counter >= patience:\n",
    "            print(\"Early stopping: validation loss has not improved in {} epochs\".format(patience))\n",
    "            break\n",
    "    #if epoch%10==0:\n",
    "    print(f\"[{epoch+1}/{epochs}] Training loss: {train_loss:.4f}\\t Validation loss: {val_loss:.4f}.\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(rn18.state_dict(), 'latest_rn18.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the loss diagram\n",
    "plt.plot(train_loss_rn18,label='Training Loss')\n",
    "plt.plot(val_loss_rn18, label='Validation Loss')\n",
    "plt.legend(loc='best')\n",
    "plt.ylabel('Mean Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.title(f\"Loss graph - ResNet18.\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_list(train_loss_rn18,'train_losses_rn18')\n",
    "write_list(val_loss_rn18,'val_loss_rn18')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rn18 = rn18\n",
    "model_rn18.load_state_dict(torch.load('best_rn18.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, ground = evaluate(model_rn18,test_loader)\n",
    "y_true_rn18 = np.concatenate(ground, axis=0)\n",
    "y_pred_rn18 = np.concatenate(pred, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_rn18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rn18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_true_rn18, y_pred_rn18))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rc_file_defaults() # to remove the sns darkgrid style\n",
    "cm = confusion_matrix(y_true_rn18, y_pred_rn18)\n",
    "classes = list(le.classes_)\n",
    "sns.heatmap(cm, annot=True, cmap='Blues', fmt='g', xticklabels=classes, yticklabels=classes)\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing accuracy = 26%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updated ResNet\n",
    "__Increasing number of Epochs to 20, increasing learning rate to 0.001__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rn18v1 = models.resnet18(pretrained=True)\n",
    "num_classes = len(le.classes_)\n",
    "# modify last layer\n",
    "rn18v1.fc = nn.Sequential(\n",
    "    nn.Linear(rn18v1.fc.in_features, num_classes),\n",
    "    nn.Softmax(dim=1)) # can remove softmax?\n",
    "# Freeze the model\n",
    "for param in rn18v1.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in rn18v1.fc.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model- only the last layer\n",
    "optimizer = optim.Adam(rn18v1.fc.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_rn18v1 = []\n",
    "val_loss_rn18v1 = []\n",
    "best_val_loss = float('inf')\n",
    "patience = 3\n",
    "early_stop_counter = 0\n",
    "rn18v1_path = 'best_rn18v1.pt'\n",
    "\n",
    "for epoch in range(20):\n",
    "    rn18v1.train()\n",
    "    batch_loss = []\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs,labels = data\n",
    "        # Move the inputs to the specified device.\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # Zero the parameter gradients.\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward step\n",
    "        outputs = rn18v1(inputs)\n",
    "        loss = criterion(outputs,labels)\n",
    "        \n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        batch_loss.append(loss.data.item())\n",
    "        \n",
    "    train_loss = np.mean(batch_loss)\n",
    "    train_loss_rn18v1.append(train_loss)\n",
    "    \n",
    "    rn18v1.eval()\n",
    "    batch_loss = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(val_loader, 0):\n",
    "            inputs,labels = data\n",
    "            # Move the inputs to the specified device.\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # forward step\n",
    "            outputs = rn18v1(inputs)\n",
    "            loss = criterion(outputs,labels)\n",
    "\n",
    "            batch_loss.append(loss.data.item())\n",
    "            \n",
    "        val_loss = np.mean(batch_loss)\n",
    "        val_loss_rn18v1.append(val_loss)\n",
    "        \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        early_stop_counter = 0\n",
    "        torch.save(rn18v1.state_dict(), rn18v1_path)\n",
    "    else:\n",
    "        early_stop_counter+=1 \n",
    "        if early_stop_counter >= patience:\n",
    "            print(\"Early stopping: validation loss has not improved in {} epochs\".format(patience))\n",
    "            break\n",
    "    #if epoch%10==0:\n",
    "    print(f\"[{epoch+1}/{20}] Training loss: {train_loss:.4f}\\t Validation loss: {val_loss:.4f}.\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(rn18v1.state_dict(), 'latest_rn18v1.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the loss diagram\n",
    "plt.plot(train_loss_rn18v1,label='Training Loss')\n",
    "plt.plot(val_loss_rn18v1, label='Validation Loss')\n",
    "plt.legend(loc='best')\n",
    "plt.ylabel('Mean Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.title(f\"Loss graph - ResNet18v1.\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_list(train_loss_rn18v1,'train_losses_rn18v1')\n",
    "write_list(val_loss_rn18v1,'val_loss_rn18v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rn18v1 = rn18v1\n",
    "model_rn18v1.load_state_dict(torch.load('best_rn18v1.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, ground = evaluate(model_rn18v1,test_loader)\n",
    "y_true_rn18v1 = np.concatenate(ground, axis=0)\n",
    "y_pred_rn18v1 = np.concatenate(pred, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_true_rn18v1, y_pred_rn18v1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rc_file_defaults() # to remove the sns darkgrid style\n",
    "cm = confusion_matrix(y_true_rn18v1, y_pred_rn18v1)\n",
    "classes = list(le.classes_)\n",
    "sns.heatmap(cm, annot=True, cmap='Blues', fmt='g', xticklabels=classes, yticklabels=classes)\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine Tuning more layers of ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rn18v2 = models.resnet18(pretrained=True)\n",
    "    \n",
    "num_classes = len(le.classes_)\n",
    "# modify last layer\n",
    "rn18v2.fc = nn.Sequential(\n",
    "    nn.Linear(rn18v2.fc.in_features, num_classes),\n",
    "    nn.Softmax(dim=1)) # can remove softmax?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, child in rn18v2.named_children():\n",
    "    if name in ['fc', 'layer4']:\n",
    "        print(name + ' is unfrozen')\n",
    "        for param in child.parameters():\n",
    "            param.requires_grad = True\n",
    "    else:\n",
    "        print(name + ' is frozen')\n",
    "        for param in child.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, rn18v2.parameters()), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_rn18v2 = []\n",
    "val_loss_rn18v2 = []\n",
    "best_val_loss = float('inf')\n",
    "patience = 3\n",
    "early_stop_counter = 0\n",
    "rn18v2_path = 'best_rn18v2.pt'\n",
    "epochs=20\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    rn18v2.train()\n",
    "    batch_loss = []\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs,labels = data\n",
    "        # Move the inputs to the specified device.\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # Zero the parameter gradients.\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward step\n",
    "        outputs = rn18v2(inputs)\n",
    "        loss = criterion(outputs,labels)\n",
    "        \n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        batch_loss.append(loss.data.item())\n",
    "        \n",
    "    train_loss = np.mean(batch_loss)\n",
    "    train_loss_rn18v2.append(train_loss)\n",
    "    \n",
    "    rn18v2.eval()\n",
    "    batch_loss = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(val_loader, 0):\n",
    "            inputs,labels = data\n",
    "            # Move the inputs to the specified device.\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # forward step\n",
    "            outputs = rn18v2(inputs)\n",
    "            loss = criterion(outputs,labels)\n",
    "\n",
    "            batch_loss.append(loss.data.item())\n",
    "            \n",
    "        val_loss = np.mean(batch_loss)\n",
    "        val_loss_rn18v2.append(val_loss)\n",
    "        \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        early_stop_counter = 0\n",
    "        torch.save(rn18v2.state_dict(), rn18v2_path)\n",
    "    else:\n",
    "        early_stop_counter+=1 \n",
    "        if early_stop_counter >= patience:\n",
    "            print(\"Early stopping: validation loss has not improved in {} epochs\".format(patience))\n",
    "            break\n",
    "    #if epoch%10==0:\n",
    "    print(f\"[{epoch+1}/{epochs}] Training loss: {train_loss:.4f}\\t Validation loss: {val_loss:.4f}.\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(rn18v2.state_dict(), 'latest_rn18v2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the loss diagram\n",
    "plt.plot(train_loss_rn18v2,label='Training Loss')\n",
    "plt.plot(val_loss_rn18v2, label='Validation Loss')\n",
    "plt.legend(loc='best')\n",
    "plt.ylabel('Mean Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.title(f\"Loss graph - ResNet18v2.\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_list(train_loss_rn18v2,'train_losses_rn18v2')\n",
    "write_list(val_loss_rn18v2,'val_loss_rn18v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rn18v2 = rn18v2\n",
    "model_rn18v2.load_state_dict(torch.load('best_rn18v2.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, ground = evaluate(model_rn18v2,test_loader)\n",
    "y_true_rn18v2 = np.concatenate(ground, axis=0)\n",
    "y_pred_rn18v2 = np.concatenate(pred, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_true_rn18v2, y_pred_rn18v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rc_file_defaults() # to remove the sns darkgrid style\n",
    "cm = confusion_matrix(y_true_rn18v2, y_pred_rn18v2)\n",
    "classes = list(le.classes_)\n",
    "sns.heatmap(cm, annot=True, cmap='Blues', fmt='g', xticklabels=classes, yticklabels=classes)\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing Accuracy 48%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__CNN: 9%__\n",
    "\n",
    "__ResNet18 with 0.0001 learning rate and 10 epochs: 26%__\n",
    "\n",
    "__ResNet18 with 0.001 learning rate and 20 epochs: 40%__\n",
    "\n",
    "__ResNet18 with 0.001 learning rate and 20 epochs and fine tuning last two layers: 48%__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade torchvision\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rn50 = models.resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_classes = len(le.classes_)\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify last layer\n",
    "rn50.fc = nn.Sequential(\n",
    "    nn.Linear(rn50.fc.in_features, num_classes),\n",
    "    nn.Softmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze the model\n",
    "for param in rn50.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in rn50.fc.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model- only the last layer\n",
    "optimizer = optim.Adam(rn50.fc.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_loss_rn50 = []\n",
    "val_loss_rn50 = []\n",
    "best_val_loss = float('inf')\n",
    "patience = 3\n",
    "early_stop_counter = 0\n",
    "rn50_path = 'best_rn50.pt'\n",
    "\n",
    "for epoch in range(20):\n",
    "    rn50.train()\n",
    "    batch_loss = []\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = rn50(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        batch_loss.append(loss.data.item())\n",
    "        \n",
    "    train_loss = np.mean(batch_loss)\n",
    "    train_loss_rn50.append(train_loss)\n",
    "    \n",
    "    rn50.eval()\n",
    "    batch_loss = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(val_loader, 0):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = rn50(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            batch_loss.append(loss.data.item())\n",
    "\n",
    "        val_loss = np.mean(batch_loss)\n",
    "        val_loss_rn50.append(val_loss)\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        early_stop_counter = 0\n",
    "        torch.save(rn50.state_dict(), rn50_path)\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "        if early_stop_counter >= patience:\n",
    "            print(\"Early stopping: validation loss has not improved in {} epochs\".format(patience))\n",
    "            break\n",
    "\n",
    "    print(f\"[{epoch+1}/{10}] Training loss: {train_loss:.4f}\\t Validation loss: {val_loss:.4f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(rn50.state_dict(), 'latest_rn50.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the loss diagram\n",
    "plt.plot(train_loss_rn50,label='Training Loss')\n",
    "plt.plot(val_loss_rn50, label='Validation Loss')\n",
    "plt.legend(loc='best')\n",
    "plt.ylabel('Mean Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.title(f\"Loss graph - ResNet50.\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_list(train_loss_rn50,'train_losses_rn50')\n",
    "write_list(val_loss_rn50,'val_loss_rn50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, ground = evaluate(model_rn50,test_loader)\n",
    "y_true_rn50 = np.concatenate(ground, axis=0)\n",
    "y_pred_rn50 = np.concatenate(pred, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_rn50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rn50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib\n",
    "print(classification_report(y_true_rn50, y_pred_rn50, zero_division=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_true_rn50, y_pred_rn50)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing accuracy = 39%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "resnet50 with 2p epochs, 00.001 lr and last 2 layers fine tuned "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "rn50v1 = models.resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(le.classes_)\n",
    "num_classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rn50v1.fc = nn.Sequential(\n",
    "    nn.Linear(rn50v1.fc.in_features, num_classes),\n",
    "    nn.Softmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, child in rn50v1.named_children():\n",
    "    if name in ['layer3', 'layer4', 'fc']:\n",
    "        print(name + ' is unfrozen')\n",
    "        for param in child.parameters():\n",
    "            param.requires_grad = True\n",
    "    else:\n",
    "        print(name + ' is frozen')\n",
    "        for param in child.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, rn50v1.parameters()), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_rn50v1 = []\n",
    "val_loss_rn50v1 = []\n",
    "best_val_loss = float('inf')\n",
    "patience = 3\n",
    "early_stop_counter = 0\n",
    "rn50v1_path = 'best_rn50v1.pt'\n",
    "\n",
    "for epoch in range(20):\n",
    "    rn50v1.train()\n",
    "    batch_loss = []\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = rn50v1(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        batch_loss.append(loss.data.item())\n",
    "        \n",
    "    train_loss = np.mean(batch_loss)\n",
    "    train_loss_rn50v1.append(train_loss)\n",
    "    \n",
    "    rn50v1.eval()\n",
    "    batch_loss = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(val_loader, 0):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = rn50v1(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            batch_loss.append(loss.data.item())\n",
    "\n",
    "        val_loss = np.mean(batch_loss)\n",
    "        val_loss_rn50v1.append(val_loss)\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        early_stop_counter = 0\n",
    "        torch.save(rn50v1.state_dict(), rn50v1_path)\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "        if early_stop_counter >= patience:\n",
    "            print(\"Early stopping: validation loss has not improved in {} epochs\".format(patience))\n",
    "            break\n",
    "\n",
    "    print(f\"[{epoch+1}/{20}] Training loss: {train_loss:.4f}\\t Validation loss: {val_loss:.4f}.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(rn50v1.state_dict(), 'latest_rn50v1.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the loss diagram\n",
    "plt.plot(train_loss_rn50v1,label='Training Loss')\n",
    "plt.plot(val_loss_rn50v1, label='Validation Loss')\n",
    "plt.legend(loc='best')\n",
    "plt.ylabel('Mean Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.title(f\"Loss graph - ResNet50v1.\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_list(train_loss_rn50v1,'train_losses_rn50v1')\n",
    "write_list(val_loss_rn50v1,'val_loss_rn50v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rn50v1 = rn50v1\n",
    "model_rn50v1.load_state_dict(torch.load('best_rn50v1.pt'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, ground = evaluate(model_rn50v1,test_loader)\n",
    "y_true_rn50v1 = np.concatenate(ground, axis=0)\n",
    "y_pred_rn50v1 = np.concatenate(pred, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_rn50v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rn50v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib\n",
    "print(classification_report(y_true_rn50v1, y_pred_rn50v1, zero_division=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rc_file_defaults() # to remove the sns darkgrid style\n",
    "cm = confusion_matrix(y_true_rn50v1, y_pred_rn50v1)\n",
    "classes = list(le.classes_)\n",
    "sns.heatmap(cm, annot=True, cmap='Blues', fmt='g', xticklabels=classes, yticklabels=classes)\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_true_rn50v1, y_pred_rn50v1)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing accuracy = 32%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
